{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37987a-5b89-4150-a76c-af21c593ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.9     |\n",
      "|    ep_rew_mean     | -0.965   |\n",
      "| time/              |          |\n",
      "|    fps             | 1216     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.5        |\n",
      "|    ep_rew_mean          | 3.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 822         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020834424 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.53       |\n",
      "|    explained_variance   | -0.0366     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "Timesteps: 5000, Avg Reward: 270.59, Elapsed: 7.75 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27.3       |\n",
      "|    ep_rew_mean          | 6.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 699        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01854989 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.48      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.11       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 15.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.9        |\n",
      "|    ep_rew_mean          | 8.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 679         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015150769 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "Timesteps: 10000, Avg Reward: 250.12, Elapsed: 15.52 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.6        |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011937483 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.43       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 53.2         |\n",
      "|    ep_rew_mean          | 19.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118686985 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.41        |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0284      |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 63.8        |\n",
      "|    ep_rew_mean          | 21.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008412747 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.39       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "Timesteps: 15000, Avg Reward: 251.25, Elapsed: 25.07 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.8        |\n",
      "|    ep_rew_mean          | 24.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833539 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.38       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.6        |\n",
      "|    ep_rew_mean          | 32.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006235481 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.37       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "Timesteps: 20000, Avg Reward: 251.17, Elapsed: 32.90 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 46.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008342308 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.36       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 99.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006438628 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.35       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 74.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008107664 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.34       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "Timesteps: 25000, Avg Reward: 250.15, Elapsed: 42.23 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 137          |\n",
      "|    ep_rew_mean          | 96.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063971775 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.33        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.8         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076647 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.4        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "Timesteps: 30000, Avg Reward: 250.21, Elapsed: 50.02 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | 129         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005176206 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.9        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 167         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008563479 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.7        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 175          |\n",
      "|    ep_rew_mean          | 168          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 608          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065546534 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.31        |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "Timesteps: 35000, Avg Reward: 256.10, Elapsed: 59.31 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 180         |\n",
      "|    ep_rew_mean          | 185         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124119 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.29       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.8        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005456373 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.27       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "Timesteps: 40000, Avg Reward: 258.81, Elapsed: 67.18 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 215          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 601          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055442844 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.25        |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 217         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008303969 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.24       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "Timesteps: 45000, Avg Reward: 260.04, Elapsed: 74.96 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 205          |\n",
      "|    ep_rew_mean          | 223          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 600          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076021133 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 231         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008652037 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.7        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 214         |\n",
      "|    ep_rew_mean          | 236         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009540381 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "Timesteps: 50000, Avg Reward: 269.34, Elapsed: 84.32 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 221         |\n",
      "|    ep_rew_mean          | 255         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011005515 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 232        |\n",
      "|    ep_rew_mean          | 274        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 599        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01742464 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.16      |\n",
      "|    explained_variance   | -0.00385   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 183        |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 0.942      |\n",
      "|    value_loss           | 228        |\n",
      "----------------------------------------\n",
      "Timesteps: 55000, Avg Reward: 274.35, Elapsed: 92.22 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 231         |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554918 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 234         |\n",
      "|    ep_rew_mean          | 294         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012329246 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 235         |\n",
      "|    ep_rew_mean          | 301         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012717144 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "Timesteps: 60000, Avg Reward: 265.93, Elapsed: 101.54 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 233         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009644408 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 306         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006893193 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "Timesteps: 65000, Avg Reward: 259.67, Elapsed: 109.37 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 222         |\n",
      "|    ep_rew_mean          | 310         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013063611 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 364         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008351481 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 213         |\n",
      "|    ep_rew_mean          | 318         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010572616 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "Timesteps: 70000, Avg Reward: 265.81, Elapsed: 118.72 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 209         |\n",
      "|    ep_rew_mean          | 313         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021059465 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | -0.00454    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 406         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 202          |\n",
      "|    ep_rew_mean          | 305          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060640676 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.16        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n",
      "Timesteps: 75000, Avg Reward: 268.63, Elapsed: 126.51 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | 295         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008710254 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 196          |\n",
      "|    ep_rew_mean          | 296          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137982415 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.16        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 252          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0261      |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 402          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 192          |\n",
      "|    ep_rew_mean          | 289          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097598415 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.16        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 337          |\n",
      "------------------------------------------\n",
      "Timesteps: 80000, Avg Reward: 261.94, Elapsed: 135.94 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 288        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 595        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00885674 |\n",
      "|    clip_fraction        | 0.0794     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.16      |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 0.944      |\n",
      "|    value_loss           | 371        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 190        |\n",
      "|    ep_rew_mean          | 290        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 595        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00730295 |\n",
      "|    clip_fraction        | 0.0549     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.15      |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 287        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 0.942      |\n",
      "|    value_loss           | 405        |\n",
      "----------------------------------------\n",
      "Timesteps: 85000, Avg Reward: 258.73, Elapsed: 143.76 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 287         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012958495 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.2        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 395         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 288         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815009 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "Timesteps: 90000, Avg Reward: 262.89, Elapsed: 151.63 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016149025 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.000977    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 184        |\n",
      "|    ep_rew_mean          | 289        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 594        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02816723 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.18      |\n",
      "|    explained_variance   | -0.00382   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    std                  | 0.949      |\n",
      "|    value_loss           | 465        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 184         |\n",
      "|    ep_rew_mean          | 290         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018863983 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | -0.000224   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 278         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n",
      "Timesteps: 95000, Avg Reward: 266.80, Elapsed: 160.95 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014238972 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.24       |\n",
      "|    explained_variance   | 0.000593    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 298         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015044652 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.26       |\n",
      "|    explained_variance   | 0.000223    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "Timesteps: 100000, Avg Reward: 263.98, Elapsed: 168.74 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 186         |\n",
      "|    ep_rew_mean          | 300         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012954173 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.26       |\n",
      "|    explained_variance   | 0.00116     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 407         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009081943 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.26       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 305         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011713678 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.26       |\n",
      "|    explained_variance   | 0.00382     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 381         |\n",
      "-----------------------------------------\n",
      "Timesteps: 105000, Avg Reward: 268.54, Elapsed: 178.13 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 305         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014384496 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.3        |\n",
      "|    explained_variance   | -0.00074    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 381         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 302         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009128599 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.31       |\n",
      "|    explained_variance   | 0.0436      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n",
      "Timesteps: 110000, Avg Reward: 263.88, Elapsed: 186.00 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 192          |\n",
      "|    ep_rew_mean          | 303          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058717206 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 315          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 415          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | 304         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004827718 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 300         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010162226 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | -0.000335   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 237         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n",
      "Timesteps: 115000, Avg Reward: 267.90, Elapsed: 195.35 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 297         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021094024 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.35       |\n",
      "|    explained_variance   | -0.00109    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 466         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 292         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008851967 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.35       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 480         |\n",
      "-----------------------------------------\n",
      "Timesteps: 120000, Avg Reward: 269.46, Elapsed: 203.19 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 188          |\n",
      "|    ep_rew_mean          | 289          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018955849 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.35        |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 189          |\n",
      "|    ep_rew_mean          | 292          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060763196 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.34        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 236          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 406          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 188          |\n",
      "|    ep_rew_mean          | 292          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067567695 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.34        |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 417          |\n",
      "------------------------------------------\n",
      "Timesteps: 125000, Avg Reward: 288.87, Elapsed: 212.58 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 298         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021007018 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.39       |\n",
      "|    explained_variance   | -0.00383    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 460         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 301         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017280644 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.41       |\n",
      "|    explained_variance   | -0.00125    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "Timesteps: 130000, Avg Reward: 284.59, Elapsed: 220.49 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 187        |\n",
      "|    ep_rew_mean          | 298        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 591        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01429758 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.43      |\n",
      "|    explained_variance   | 0.000183   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 101        |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 399        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 296         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004574809 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.44       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 241         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 422         |\n",
      "-----------------------------------------\n",
      "Timesteps: 135000, Avg Reward: 296.57, Elapsed: 228.39 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 193          |\n",
      "|    ep_rew_mean          | 298          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027604308 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.44        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 90           |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00783     |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 192          |\n",
      "|    ep_rew_mean          | 298          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047538625 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.44        |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 316          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00949     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 443          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 191          |\n",
      "|    ep_rew_mean          | 306          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057980483 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.44        |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 153          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00969     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 386          |\n",
      "------------------------------------------\n",
      "Timesteps: 140000, Avg Reward: 301.54, Elapsed: 237.81 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 302         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689799 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.44       |\n",
      "|    explained_variance   | 0.00102     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 299         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004152422 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 447         |\n",
      "-----------------------------------------\n",
      "Timesteps: 145000, Avg Reward: 303.61, Elapsed: 245.72 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 300         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013116563 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 395         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 296         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016154539 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.00531     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 191          |\n",
      "|    ep_rew_mean          | 295          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058541466 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.46        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 399          |\n",
      "------------------------------------------\n",
      "Timesteps: 150000, Avg Reward: 301.81, Elapsed: 255.14 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 296         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009973938 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 453         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012158398 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.47       |\n",
      "|    explained_variance   | 0.00325     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 456         |\n",
      "-----------------------------------------\n",
      "Timesteps: 155000, Avg Reward: 305.63, Elapsed: 263.03 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 308         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012613099 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.48       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 407         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 307         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022360716 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.47       |\n",
      "|    explained_variance   | 0.00248     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 419         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 308         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016447863 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.00147     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 509         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 517         |\n",
      "-----------------------------------------\n",
      "Timesteps: 160000, Avg Reward: 324.88, Elapsed: 272.54 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 185          |\n",
      "|    ep_rew_mean          | 303          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 590          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062697446 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.47        |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 382          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006397118 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 486         |\n",
      "-----------------------------------------\n",
      "Timesteps: 165000, Avg Reward: 365.67, Elapsed: 280.47 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 182         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015397243 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.48       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 475         |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 562         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 182         |\n",
      "|    ep_rew_mean          | 305         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009572695 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 462         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018324805 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.53       |\n",
      "|    explained_variance   | 0.00204     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 495         |\n",
      "-----------------------------------------\n",
      "Timesteps: 170000, Avg Reward: 323.15, Elapsed: 289.96 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011712002 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.52       |\n",
      "|    explained_variance   | -0.00215    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 436         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 312         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020076957 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | 0.000818    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 357         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 525         |\n",
      "-----------------------------------------\n",
      "Timesteps: 175000, Avg Reward: 365.54, Elapsed: 297.87 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 187        |\n",
      "|    ep_rew_mean          | 315        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 589        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01279969 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.46      |\n",
      "|    explained_variance   | 0.00479    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 303        |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 454        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 317         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014094507 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.48       |\n",
      "|    explained_variance   | 0.000905    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 495         |\n",
      "-----------------------------------------\n",
      "Timesteps: 180000, Avg Reward: 365.09, Elapsed: 305.76 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 323         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011915207 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 320         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011456285 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.0125      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 534         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 193        |\n",
      "|    ep_rew_mean          | 326        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 589        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007422 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.5       |\n",
      "|    explained_variance   | 0.758      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 432        |\n",
      "----------------------------------------\n",
      "Timesteps: 185000, Avg Reward: 365.62, Elapsed: 315.19 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 324         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639081 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 439         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 325         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013037663 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | -0.00216    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "Timesteps: 190000, Avg Reward: 363.42, Elapsed: 323.13 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 326          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115866475 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.49        |\n",
      "|    explained_variance   | 0.0112       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0299      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 496          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 327         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012558961 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | 0.00359     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 617         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 335         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012797061 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | -0.00146    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 454         |\n",
      "-----------------------------------------\n",
      "Timesteps: 195000, Avg Reward: 377.68, Elapsed: 332.58 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 330         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009863056 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 435         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 192          |\n",
      "|    ep_rew_mean          | 335          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073439563 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.5         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "Timesteps: 200000, Avg Reward: 393.04, Elapsed: 340.49 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 341         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009826183 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 350         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008500991 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 354         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007446741 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n",
      "Timesteps: 205000, Avg Reward: 402.68, Elapsed: 349.94 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 358         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008094253 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 199          |\n",
      "|    ep_rew_mean          | 360          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117071625 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.5         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.0243      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "Timesteps: 210000, Avg Reward: 399.09, Elapsed: 357.90 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 204         |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011424049 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010534369 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.47       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "Timesteps: 215000, Avg Reward: 408.36, Elapsed: 365.87 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 361         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009596362 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 205         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011810522 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008938923 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.43       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "Timesteps: 220000, Avg Reward: 417.69, Elapsed: 375.44 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 366         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010924632 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.42       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 366         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014059173 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.42       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "Timesteps: 225000, Avg Reward: 444.94, Elapsed: 383.47 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010623649 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.41       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012237608 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.41       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013947915 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.42       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.6         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "Timesteps: 230000, Avg Reward: 437.49, Elapsed: 393.04 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 363         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010556045 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.42       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 361         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011027027 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.43       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "Timesteps: 235000, Avg Reward: 438.84, Elapsed: 401.09 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 194        |\n",
      "|    ep_rew_mean          | 356        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 586        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 401        |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01243056 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.42      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0231    |\n",
      "|    std                  | 0.982      |\n",
      "|    value_loss           | 33.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | 359         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009843765 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.39       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 361         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016067486 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.34       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "Timesteps: 240000, Avg Reward: 435.07, Elapsed: 410.64 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013165532 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.3        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 198        |\n",
      "|    ep_rew_mean          | 367        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 586        |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 415        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01291682 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.28      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    std                  | 0.96       |\n",
      "|    value_loss           | 38.3       |\n",
      "----------------------------------------\n",
      "Timesteps: 245000, Avg Reward: 433.12, Elapsed: 418.66 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 368         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017281946 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.27       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 367         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012897886 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.26       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 198          |\n",
      "|    ep_rew_mean          | 371          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 586          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 426          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153162945 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.26        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.0355      |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "Timesteps: 250000, Avg Reward: 423.60, Elapsed: 428.28 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 370         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013023361 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.24       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016755652 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n",
      "Timesteps: 255000, Avg Reward: 391.98, Elapsed: 436.29 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 375         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273715 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 377         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013342198 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n",
      "Timesteps: 260000, Avg Reward: 414.21, Elapsed: 444.30 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 375         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015548432 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.37        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 378         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013647106 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.13       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 381         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013542085 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.1        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.13        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "Timesteps: 265000, Avg Reward: 425.20, Elapsed: 453.97 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 383         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013497023 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.06       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 387         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016401215 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.01       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "Timesteps: 270000, Avg Reward: 384.58, Elapsed: 461.95 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 394         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017016612 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.95       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.65        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 9.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 395         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009834319 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.92       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.5        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 397         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014258571 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.89       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "Timesteps: 275000, Avg Reward: 365.00, Elapsed: 471.47 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 399         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014583152 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.87       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.77        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 400         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012862903 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.82       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.99        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "Timesteps: 280000, Avg Reward: 373.55, Elapsed: 479.48 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 399         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015162826 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.8        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.2         |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    std                  | 0.887       |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 396         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013367921 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.8        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 399         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016138583 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.77       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "Timesteps: 285000, Avg Reward: 427.61, Elapsed: 488.92 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 398         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016396573 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.76       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | 399         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012061812 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.73       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "Timesteps: 290000, Avg Reward: 397.88, Elapsed: 496.88 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | 402         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014948854 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.68       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 405         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016553748 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.66       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 199        |\n",
      "|    ep_rew_mean          | 411        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 504        |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01703484 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.63      |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.72       |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    std                  | 0.863      |\n",
      "|    value_loss           | 13.1       |\n",
      "----------------------------------------\n",
      "Timesteps: 295000, Avg Reward: 441.38, Elapsed: 506.33 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 196          |\n",
      "|    ep_rew_mean          | 410          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 508          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130591225 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.0272      |\n",
      "|    std                  | 0.861        |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 197        |\n",
      "|    ep_rew_mean          | 413        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 511        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01576477 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.62      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.9       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 0.863      |\n",
      "|    value_loss           | 127        |\n",
      "----------------------------------------\n",
      "Timesteps: 300000, Avg Reward: 436.31, Elapsed: 514.38 sec\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 199          |\n",
      "|    ep_rew_mean          | 418          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 515          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133522265 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.63        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.0292      |\n",
      "|    std                  | 0.862        |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 418         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012104489 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.59       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "Timesteps: 305000, Avg Reward: 430.47, Elapsed: 522.43 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 421         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014111736 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.56       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 418         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 525         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014340731 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.56       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.93        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 418         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641573 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.58       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "Timesteps: 310000, Avg Reward: 441.86, Elapsed: 532.00 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 196        |\n",
      "|    ep_rew_mean          | 420        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 533        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01637847 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.58      |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.71       |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    std                  | 0.855      |\n",
      "|    value_loss           | 17.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 194        |\n",
      "|    ep_rew_mean          | 419        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 536        |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01894154 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.55      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.62       |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    std                  | 0.85       |\n",
      "|    value_loss           | 34.8       |\n",
      "----------------------------------------\n",
      "Timesteps: 315000, Avg Reward: 429.72, Elapsed: 539.96 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 417         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015742086 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.24        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 419         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013940135 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.5        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 421         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015440212 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.48       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "Timesteps: 320000, Avg Reward: 449.16, Elapsed: 549.47 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 419         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013238233 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.45       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 419         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014999784 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "Timesteps: 325000, Avg Reward: 481.23, Elapsed: 557.57 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 427         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014861097 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.37       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 195       |\n",
      "|    ep_rew_mean          | 434       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 583       |\n",
      "|    iterations           | 160       |\n",
      "|    time_elapsed         | 561       |\n",
      "|    total_timesteps      | 327680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0183651 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.34     |\n",
      "|    explained_variance   | 0.961     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.81      |\n",
      "|    n_updates            | 1590      |\n",
      "|    policy_gradient_loss | -0.0216   |\n",
      "|    std                  | 0.822     |\n",
      "|    value_loss           | 54.5      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 196        |\n",
      "|    ep_rew_mean          | 439        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01964094 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.32      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    std                  | 0.82       |\n",
      "|    value_loss           | 44.5       |\n",
      "----------------------------------------\n",
      "Timesteps: 330000, Avg Reward: 515.01, Elapsed: 567.19 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 196        |\n",
      "|    ep_rew_mean          | 442        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 568        |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01648599 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.29      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    std                  | 0.814      |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 448         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016555648 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.27       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "Timesteps: 335000, Avg Reward: 541.13, Elapsed: 575.29 sec\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 197        |\n",
      "|    ep_rew_mean          | 453        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 164        |\n",
      "|    time_elapsed         | 576        |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01596896 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.24      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 1630       |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    std                  | 0.808      |\n",
      "|    value_loss           | 32.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 467         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027650336 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 0.811       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 205        |\n",
      "|    ep_rew_mean          | 481        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 582        |\n",
      "|    total_timesteps      | 339968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01617021 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.25      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.7       |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    std                  | 0.812      |\n",
      "|    value_loss           | 61.3       |\n",
      "----------------------------------------\n",
      "Timesteps: 340000, Avg Reward: 558.69, Elapsed: 584.92 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 206         |\n",
      "|    ep_rew_mean          | 488         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016415233 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    std                  | 0.813       |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 208         |\n",
      "|    ep_rew_mean          | 497         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012374902 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "Timesteps: 345000, Avg Reward: 551.76, Elapsed: 593.00 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 506         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016230157 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    std                  | 0.81        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 212         |\n",
      "|    ep_rew_mean          | 511         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014293395 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 0.808       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "Timesteps: 350000, Avg Reward: 690.04, Elapsed: 601.25 sec\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 214         |\n",
      "|    ep_rew_mean          | 519         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014709471 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.21       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 0.808       |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 534         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017685752 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.2        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 0.805       |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "import psutil\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "# ------------------------------\n",
    "# Global Variables for Monitoring\n",
    "# ------------------------------\n",
    "cpu_usages = []\n",
    "gpu_usages = []\n",
    "monitoring = True\n",
    "\n",
    "def monitor_usage(interval=1):\n",
    "    \"\"\"Monitor CPU and GPU usage every 'interval' seconds.\"\"\"\n",
    "    global monitoring\n",
    "    while monitoring:\n",
    "        cpu_percent = psutil.cpu_percent(interval=interval)\n",
    "        cpu_usages.append(cpu_percent)\n",
    "        try:\n",
    "            gpus = GPUtil.getGPUs()\n",
    "            gpu_percent = gpus[0].load * 100 if gpus else 0\n",
    "        except Exception:\n",
    "            gpu_percent = 0\n",
    "        gpu_usages.append(gpu_percent)\n",
    "\n",
    "# ------------------------------\n",
    "# Domain Randomization Wrapper\n",
    "# ------------------------------\n",
    "class DomainRandomizationWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Wraps an environment to randomize certain domain parameters at every reset.\n",
    "    For Walker2D (a MuJoCo environment), this example randomizes:\n",
    "      - Gravity (along the z-axis)\n",
    "      - Friction for the first geometry (as an example)\n",
    "      - A scaling factor for all body masses\n",
    "    \"\"\"\n",
    "    def __init__(self, env,\n",
    "                 gravity_range=(-10, -9),\n",
    "                 friction_range=(0.5, 1.5),\n",
    "                 mass_range=(0.8, 1.2)):\n",
    "        super(DomainRandomizationWrapper, self).__init__(env)\n",
    "        self.gravity_range = gravity_range\n",
    "        self.friction_range = friction_range\n",
    "        self.mass_range = mass_range\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Check if the environment provides access to the simulation (MuJoCo)\n",
    "        if hasattr(self.env, \"sim\"):\n",
    "            # Randomize gravity (usually gravity is along the z axis)\n",
    "            new_gravity = np.random.uniform(*self.gravity_range)\n",
    "            self.env.sim.model.opt.gravity[2] = new_gravity\n",
    "\n",
    "            # Randomize friction on the first geom as an example\n",
    "            new_friction = np.random.uniform(*self.friction_range)\n",
    "            # Typically, friction parameters for a geom are an array; here we update the first entry.\n",
    "            self.env.sim.model.geom_friction[0] = np.array([new_friction, 0.005, 0.0001])\n",
    "\n",
    "            # Randomize the mass scaling for all bodies\n",
    "            mass_scale = np.random.uniform(*self.mass_range)\n",
    "            for i in range(self.env.sim.model.nbody):\n",
    "                # Multiply the original mass by a scaling factor; for reproducibility you could also store the original values.\n",
    "                self.env.sim.model.body_mass[i] *= mass_scale\n",
    "\n",
    "        # Reset the underlying environment\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation Metrics Callback for PPO Training\n",
    "# ------------------------------\n",
    "class EvaluationMetricsCallback(BaseCallback):\n",
    "    def __init__(self, eval_env, eval_freq: int, n_eval_episodes: int = 5, verbose: int = 1):\n",
    "        super(EvaluationMetricsCallback, self).__init__(verbose)\n",
    "        self.eval_env = eval_env\n",
    "        self.eval_freq = eval_freq\n",
    "        self.n_eval_episodes = n_eval_episodes\n",
    "        self.eval_rewards = []   # List to store average reward at evaluation points\n",
    "        self.eval_timesteps = [] # Timesteps corresponding to each evaluation\n",
    "        self.eval_wall_times = []# Elapsed wall-clock time at evaluation\n",
    "        self.start_time = None\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps % self.eval_freq == 0:\n",
    "            rewards = []\n",
    "            for _ in range(self.n_eval_episodes):\n",
    "                obs, info = self.eval_env.reset()\n",
    "                ep_reward = 0.0\n",
    "                done = False\n",
    "                while not done:\n",
    "                    action, _ = self.model.predict(obs, deterministic=True)\n",
    "                    obs, reward, done, truncated, info = self.eval_env.step(action)\n",
    "                    done = done or truncated\n",
    "                    ep_reward += reward\n",
    "                rewards.append(ep_reward)\n",
    "            avg_reward = np.mean(rewards)\n",
    "            self.eval_rewards.append(avg_reward)\n",
    "            self.eval_timesteps.append(self.num_timesteps)\n",
    "            elapsed = time.time() - self.start_time\n",
    "            self.eval_wall_times.append(elapsed)\n",
    "            print(f\"Timesteps: {self.num_timesteps}, Avg Reward: {avg_reward:.2f}, Elapsed: {elapsed:.2f} sec\")\n",
    "        return True\n",
    "\n",
    "# ------------------------------\n",
    "# Create and Wrap Walker2D Environment with Domain Randomization\n",
    "# ------------------------------\n",
    "# Note: You may need to install and configure Mujoco and gymnasium's mujoco environments.\n",
    "env_id = \"Walker2d-v5\"  # or the appropriate id for your Walker2D environment\n",
    "base_env = gym.make(env_id)\n",
    "# Wrap with domain randomization to improve generalization\n",
    "env = DomainRandomizationWrapper(base_env,\n",
    "                                 gravity_range=(-10, -9),      # randomized gravity\n",
    "                                 friction_range=(0.5, 1.5),       # randomized friction coefficient\n",
    "                                 mass_range=(0.8, 1.2))           # randomized mass scaling\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize PPO Model for Walker2D with Domain Randomization\n",
    "# ------------------------------\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# ------------------------------\n",
    "# Set Up Callbacks for Training\n",
    "# ------------------------------\n",
    "# Here, as an example, we only use the evaluation callback.\n",
    "eval_callback = EvaluationMetricsCallback(env, eval_freq=5000, n_eval_episodes=5, verbose=1)\n",
    "callback = CallbackList([eval_callback])\n",
    "\n",
    "# ------------------------------\n",
    "# Start Monitoring CPU/GPU Usage and Train the Model\n",
    "# ------------------------------\n",
    "monitor_thread = threading.Thread(target=monitor_usage, args=(1,), daemon=True)\n",
    "monitor_thread.start()\n",
    "\n",
    "total_timesteps = 3e6  # Total training timesteps (adjust based on your available resources)\n",
    "start_time = time.time()\n",
    "model.learn(total_timesteps=int(total_timesteps), callback=callback)\n",
    "model.save(\"walker2d_domain_randomized_v3.zip\")\n",
    "end_time = time.time()\n",
    "training_time_sec = end_time - start_time\n",
    "\n",
    "monitoring = False\n",
    "monitor_thread.join()\n",
    "env.close()\n",
    "\n",
    "# ------------------------------\n",
    "# Compute Energy Metrics and Print Summary\n",
    "# ------------------------------\n",
    "avg_cpu = np.mean(cpu_usages) if cpu_usages else 50.0\n",
    "avg_gpu = np.mean(gpu_usages) if gpu_usages else 50.0\n",
    "\n",
    "# Hardware assumptions: i7-10700K ~125W, RTX 2080 Super ~250W.\n",
    "power_cpu_max = 125  # Watts\n",
    "power_gpu_max = 250  # Watts\n",
    "cpu_power = (avg_cpu / 100) * power_cpu_max\n",
    "gpu_power = (avg_gpu / 100) * power_gpu_max\n",
    "total_power = cpu_power + gpu_power  # in Watts\n",
    "training_hours = training_time_sec / 3600\n",
    "energy_kwh = (total_power * training_hours) / 1000  # in kWh\n",
    "\n",
    "final_reward = eval_callback.eval_rewards[-1] if eval_callback.eval_rewards else None\n",
    "\n",
    "metrics = {\n",
    "    \"final_reward\": final_reward,\n",
    "    \"training_time_sec\": training_time_sec,\n",
    "    \"avg_cpu\": avg_cpu,\n",
    "    \"avg_gpu\": avg_gpu,\n",
    "    \"energy_kwh\": energy_kwh,\n",
    "    \"eval_timesteps\": eval_callback.eval_timesteps,\n",
    "    \"eval_rewards\": eval_callback.eval_rewards,\n",
    "    \"eval_wall_times\": eval_callback.eval_wall_times\n",
    "}\n",
    "\n",
    "print(\"Training complete, and model saved as 'walker2d_domain_randomized.zip'.\")\n",
    "print(\"=== Metrics Summary ===\")\n",
    "print(f\"Final Reward: {metrics['final_reward']}\")\n",
    "print(f\"Training Time: {training_time_sec:.2f} sec ({training_hours:.2f} hours)\")\n",
    "print(f\"Average CPU Usage: {avg_cpu:.2f}% -> CPU Power: {cpu_power:.2f} W\")\n",
    "print(f\"Average GPU Usage: {avg_gpu:.2f}% -> GPU Power: {gpu_power:.2f} W\")\n",
    "print(f\"Estimated Energy Consumption: {energy_kwh:.3f} kWh\")\n",
    "\n",
    "# ------------------------------\n",
    "# Save Metrics to a File\n",
    "# ------------------------------\n",
    "metrics_file = \"training_metrics_walker2d_domain_randomized_v3.json\"\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "print(f\"Metrics saved to {metrics_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a642e4a-2761-4bd9-b800-7210c3726fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
